# DocumentaciÃ³n RAG Agent

Un agente inteligente de documentaciÃ³n que utiliza RAG (Retrieval-Augmented Generation) para responder preguntas sobre documentaciÃ³n tÃ©cnica.

## ğŸ—ï¸ Arquitectura

- **Backend**: FastAPI (Python)
- **Base de Datos**: PostgreSQL
- **Base de Datos Vectorial**: ChromaDB
- **OrquestaciÃ³n**: Celery + Redis
- **LLM**: Ollama (desarrollo) / OpenAI/Anthropic (producciÃ³n)
- **Embeddings**: sentence-transformers/all-MiniLM-L6-v2

## ğŸš€ InstalaciÃ³n

### Prerrequisitos

- Python 3.9+
- PostgreSQL
- Redis
- Ollama (para desarrollo local)

### ConfiguraciÃ³n

1. **Clonar el repositorio**
```bash
git clone <repository-url>
cd documentacion-rag-agent
```

2. **Crear entorno virtual**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# o
venv\Scripts\activate  # Windows
```

3. **Instalar dependencias**
```bash
pip install -r requirements.txt
```

4. **Configurar variables de entorno**
```bash
cp .env.example .env
# Editar .env con tus configuraciones
```

5. **Configurar base de datos**
```bash
# Crear base de datos PostgreSQL
createdb documentacion_rag

# Ejecutar migraciones
alembic upgrade head
```

6. **Instalar Playwright**
```bash
playwright install
```

## ğŸƒâ€â™‚ï¸ EjecuciÃ³n

### Desarrollo

1. **Iniciar Redis**
```bash
redis-server
```

2. **Iniciar Celery worker**
```bash
celery -A app.celery_app worker --loglevel=info
```

3. **Iniciar FastAPI**
```bash
uvicorn app.main:app --reload
```

4. **Iniciar Ollama (opcional)**
```bash
ollama run llama2
```

### ProducciÃ³n

```bash
# Usar gunicorn para producciÃ³n
gunicorn app.main:app -w 4 -k uvicorn.workers.UvicornWorker
```

## ğŸ“š Uso de la API

### 1. Procesar DocumentaciÃ³n

```bash
curl -X POST "http://localhost:8000/api/v1/process-documentation" \
  -H "Content-Type: application/json" \
  -d '{
    "url": "https://docs.example.com",
    "chatId": "chat_123"
  }'
```

### 2. Verificar Estado de Procesamiento

```bash
curl "http://localhost:8000/api/v1/processing-status/chat_123"
```

### 3. Hacer Pregunta

```bash
curl -X POST "http://localhost:8000/api/v1/chat/chat_123" \
  -H "Content-Type: application/json" \
  -d '{
    "question": "Â¿CÃ³mo configurar la base de datos?"
  }'
```

### 4. Obtener Historial

```bash
curl "http://localhost:8000/api/v1/chat-history/chat_123"
```

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno (.env)

```env
# Base de datos
DATABASE_URL=postgresql://user:password@localhost/documentacion_rag

# Redis
REDIS_URL=redis://localhost:6379

# LLM
LLM_PROVIDER=ollama  # ollama, openai, anthropic
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama2
OPENAI_API_KEY=your_openai_key
ANTHROPIC_API_KEY=your_anthropic_key

# ChromaDB
CHROMA_PERSIST_DIRECTORY=./chroma_db

# ConfiguraciÃ³n de la aplicaciÃ³n
DEBUG=True
LOG_LEVEL=INFO
```

## ğŸ§ª Testing

```bash
# Ejecutar tests
pytest

# Ejecutar tests con coverage
pytest --cov=app
```

## ğŸ“ Estructura del Proyecto

```
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                 # FastAPI app
â”‚   â”œâ”€â”€ celery_app.py          # Celery configuration
â”‚   â”œâ”€â”€ models/                # SQLAlchemy models
â”‚   â”œâ”€â”€ schemas/               # Pydantic schemas
â”‚   â”œâ”€â”€ services/              # Business logic
â”‚   â”œâ”€â”€ agents/                # LangGraph agents
â”‚   â”œâ”€â”€ tasks/                 # Celery tasks
â”‚   â””â”€â”€ utils/                 # Utilities
â”œâ”€â”€ alembic/                   # Database migrations
â”œâ”€â”€ tests/                     # Test files
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env.example
â””â”€â”€ README.md
```

## ğŸ¤ ContribuciÃ³n

1. Fork el proyecto
2. Crear una rama para tu feature (`git checkout -b feature/AmazingFeature`)
3. Commit tus cambios (`git commit -m 'Add some AmazingFeature'`)
4. Push a la rama (`git push origin feature/AmazingFeature`)
5. Abrir un Pull Request

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la Licencia MIT - ver el archivo [LICENSE](LICENSE) para detalles. 